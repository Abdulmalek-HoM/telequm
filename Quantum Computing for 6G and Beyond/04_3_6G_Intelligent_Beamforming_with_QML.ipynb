{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook 4.3: 6G Intelligent Beamforming with QML**\n",
    "\n",
    "**Objective:** This notebook introduces Quantum Machine Learning (QML) by applying a **Quantum Support Vector Classifier (QSVC)** to a simulated **intelligent beamforming** problem. We will generate a synthetic dataset, find the optimal model complexity through hyperparameter tuning, and train both a classical SVM and a QSVC to compare their performance. ðŸ§ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. The Telecom Problem: Intelligent Beamforming**\n",
    "\n",
    "In 6G networks, base stations use beamforming to precisely direct radio signals to users. The optimal beam configuration (e.g., its angle and width) depends on complex factors like user location, obstacles, and signal reflections. This can be framed as a **classification problem**: based on input data (like user coordinates and channel state information), the system must choose the best beam configuration from a predefined set.\n",
    "\n",
    "We will simulate a scenario with two classes of users, each requiring a different beamforming setup. Our goal is to train a model that can accurately classify a new user and assign the correct beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Setup: Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Core Python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn for classical ML and data generation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Generating a Synthetic Beamforming Dataset**\n",
    "\n",
    "We will create a synthetic dataset where the features could represent user coordinates or channel characteristics. The dataset is intentionally made non-linearly separable to demonstrate the power of kernel methods like SVM and QSVC."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate a dataset with 2 features for easy visualization\n",
    "X, y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    random_state=42,\n",
    "    n_clusters_per_class=2\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Plot the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "plt.title(\"Synthetic Beamforming Dataset\")\n",
    "plt.xlabel(\"Feature 1 (e.g., User Azimuth)\")\n",
    "plt.ylabel(\"Feature 2 (e.g., Signal Strength)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Classical Benchmark: Support Vector Machine (SVM)**\n",
    "\n",
    "First, let's train a classical SVM with a standard Radial Basis Function (RBF) kernel to see how it performs on our dataset. This will be our baseline."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create and train the classical SVM\n",
    "classical_svm = SVC(kernel='rbf')\n",
    "classical_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "classical_preds = classical_svm.predict(X_test)\n",
    "classical_accuracy = accuracy_score(y_test, classical_preds)\n",
    "\n",
    "print(f\"Classical SVM Accuracy: {classical_accuracy * 100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Quantum Approach: Hyperparameter Tuning for QSVC**\n",
    "\n",
    "Instead of guessing the best complexity for our quantum model, we will systematically test a range of values for the `reps` hyperparameter in our `ZZFeatureMap`. This allows us to find the 'sweet spot' that avoids both underfitting and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "accuracies = {}\n",
    "reps_to_test = [1, 2, 3, 4, 5] # Test a range of complexity values\n",
    "\n",
    "for reps_val in reps_to_test:\n",
    "    print(f\"--- Testing with reps = {reps_val} ---\")\n",
    "    \n",
    "    # 1. Define the Feature Map\n",
    "    num_features = X.shape[1]\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=reps_val)\n",
    "\n",
    "    # 2. Define the Sampler and Fidelity object\n",
    "    sampler = Sampler()\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "\n",
    "    # 3. Instantiate the Quantum Kernel\n",
    "    quantum_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "\n",
    "    # 4. Instantiate and Train the QSVC\n",
    "    qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "    qsvc.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Make predictions and store accuracy\n",
    "    qsvc_preds = qsvc.predict(X_test)\n",
    "    accuracies[reps_val] = accuracy_score(y_test, qsvc_preds)\n",
    "    print(f\"Accuracy for reps = {reps_val}: {accuracies[reps_val] * 100:.2f}%\")\n",
    "\n",
    "# --- Plot the tuning results ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(accuracies.keys()), list(accuracies.values()), marker='o', linestyle='--')\n",
    "plt.title(\"QSVC Accuracy vs. Feature Map Repetitions ('reps')\")\n",
    "plt.xlabel(\"Number of Reps\")\n",
    "plt.ylabel(\"Accuracy on Test Set\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Find the best result and re-train the model for visualization ---\n",
    "best_reps = max(accuracies, key=accuracies.get)\n",
    "best_accuracy = accuracies[best_reps]\n",
    "print(f\"\\nBest result found with reps = {best_reps}, achieving an accuracy of {best_accuracy * 100:.2f}%.\")\n",
    "\n",
    "print(f\"\\nRe-training the best model with reps = {best_reps} for visualization...\")\n",
    "best_feature_map = ZZFeatureMap(feature_dimension=num_features, reps=best_reps)\n",
    "best_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=best_feature_map)\n",
    "qsvc = QSVC(quantum_kernel=best_kernel)\n",
    "qsvc.fit(X_train, y_train)\n",
    "qsvc_preds = qsvc.predict(X_test) # This creates the variable for the next cell\n",
    "print(\"Best model is ready for plotting.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Visualizing the Best Model's Predictions**\n",
    "\n",
    "Now we visualize the performance of our best-performing QSVC model. Instead of plotting the full decision boundary (which is computationally explosive), we will plot the test data points and highlight any points that the model misclassified. This is a fast and effective way to see the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the test data points, colored by their true label\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm, edgecolors='k', label='True Labels')\n",
    "\n",
    "# Find where the QSVC made incorrect predictions\n",
    "incorrect_indices = np.where(y_test != qsvc_preds)[0]\n",
    "\n",
    "# Highlight the incorrect predictions with large 'X' markers\n",
    "plt.scatter(\n",
    "    X_test[incorrect_indices, 0],\n",
    "    X_test[incorrect_indices, 1],\n",
    "    s=250,\n",
    "    facecolors='none',\n",
    "    edgecolors='black',\n",
    "    linewidths=2,\n",
    "    marker='X',\n",
    "    label='Incorrect Predictions'\n",
    ")\n",
    "\n",
    "# Use the 'best_accuracy' variable in the title\n",
    "plt.title(f'QSVC Predictions on Test Data (Best Accuracy: {best_accuracy*100:.2f}%)')\n",
    "plt.xlabel('Feature 1 (e.g., User Azimuth)')\n",
    "plt.ylabel('Feature 2 (e.g., Signal Strength)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Conclusion and Telecom Impact**\n",
    "\n",
    "In this notebook, we implemented a Quantum Support Vector Classifier and performed hyperparameter tuning to find the optimal model complexity. We compared this to a classical SVM on a simulated beamforming classification task.\n",
    "\n",
    "The true potential for quantum advantage with QML lies in problems with a very high number of features, where classical computers struggle to find patterns. In 6G, this could include:\n",
    "\n",
    "* **Complex Channel State Information (CSI):** Using dozens or hundreds of CSI parameters as features to predict the optimal beam configuration.\n",
    "* **Dynamic Spectrum Access:** Classifying spectrum availability based on complex, high-dimensional interference data.\n",
    "* **Network Security:** Detecting sophisticated attacks by classifying network traffic patterns with many features.\n",
    "\n",
    "This notebook provides the foundational understanding of how to build and tune QML models for future intelligent and autonomous telecom networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
